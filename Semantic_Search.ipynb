{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "20VkCAgjdBmG"
   },
   "outputs": [],
   "source": [
    "def read_raw_csv(file_name):\n",
    "    with open(file_name, 'r',encoding=\"latin1\") as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        count = 0\n",
    "\n",
    "        # count number of rows\n",
    "        for row in csvreader:\n",
    "          count += 1\n",
    "        return count-1, len(row)  # -1 is for discarding header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXcnFHlzfn0Q",
    "outputId": "1538fbe0-cf4e-4237-860b-049255bd3287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264216 7\n",
      "1048575 6\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "number_of_ques, number_of_columns = read_raw_csv(r'C:\\AppliedAI\\SearchEngine_QA-20220522T094532Z-001\\SearchEngine_QA\\archive\\Questions.csv')\n",
    "print(number_of_ques, number_of_columns)\n",
    "number_of_ans, number_of_columns = read_raw_csv(r'C:\\AppliedAI\\SearchEngine_QA-20220522T094532Z-001\\SearchEngine_QA\\archive\\Answers.csv')\n",
    "print(number_of_ans, number_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4dvLdhaSfIU",
    "outputId": "4d7b4ecd-c3d0-4ed5-fb87-859eccd92c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ES!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "#es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "if es.ping():\n",
    "  print('Connected to ES!')\n",
    "else:\n",
    "  print('Could not connect!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FYBQ4bfOilxW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Mapping: Structure of the index\n",
    "# Property/Field: name and type  \n",
    "b = {\"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "              \"type\": \"text\"\n",
    "            },\n",
    "            \"title_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 512\n",
    "        }\n",
    "    }\n",
    "     }\n",
    "   }\n",
    "ret = es.indices.create(index='questions-index', ignore=400, body=b) #400 caused by IndexAlreadyExistsException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load USE4 model\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n"
     ]
    }
   ],
   "source": [
    "#Insert 200000 datapoints into elastic database\n",
    "NUM_QUESTIONS_INDEXED = 200000\n",
    "\n",
    "# Col-Names: Id,OwnerUserId,CreationDate,ClosedDate,Score,Title,Body\n",
    "cnt=0\n",
    "with open(r'C:\\AppliedAI\\SearchEngine_QA-20220522T094532Z-001\\SearchEngine_QA\\archive\\Questions.csv', encoding=\"latin1\") as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',' )\n",
    "    next(readCSV, None)  # skip the headers \n",
    "    for row in readCSV:\n",
    "        #print(row[0], row[5])\n",
    "        doc_id = row[0];\n",
    "        title = row[5];\n",
    "        vec = tf.make_ndarray(tf.make_tensor_proto(embed([title]))).tolist()[0]\n",
    "\n",
    "        b = {\"title\":title,\n",
    "            \"title_vector\":vec,\n",
    "            }\n",
    "        \n",
    "        res = es.index(index=\"questions-index\", id=doc_id, body=b)\n",
    "        #print(res)\n",
    "\n",
    "        # keep count of # rows processed\n",
    "        cnt += 1\n",
    "        if cnt == NUM_QUESTIONS_INDEXED:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Semantic_Search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
